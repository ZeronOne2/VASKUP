#!/usr/bin/env python3
"""ì„¤ëª… ìŠ¤í¬ë˜í•‘ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸"""

import json
import sys
import os

sys.path.append("src")

from patent_search.patent_parser import PatentDataProcessor
from patent_search.description_scraper import GooglePatentsDescriptionScraper


def test_description_scraping_and_chunking():
    """ì‹¤ì œ ì„¤ëª… ìŠ¤í¬ë˜í•‘ í›„ ì²­í‚¹ í…ŒìŠ¤íŠ¸"""

    print("ğŸ” ì„¤ëª… ìŠ¤í¬ë˜í•‘ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. ìºì‹œì—ì„œ description_linkê°€ ìˆëŠ” ìƒ˜í”Œ ì°¾ê¸°
    with open("src/cache/patent_cache.json", "r", encoding="utf-8") as f:
        cache_data = json.load(f)

    samples_with_links = []
    for key, item in cache_data.items():
        if "data" not in item:
            continue
        data = item["data"]
        if "description_link" in data and data["description_link"]:
            patent_number = None
            if "raw_data" in data and "publication_number" in data["raw_data"]:
                patent_number = data["raw_data"]["publication_number"]
            elif "google_patents_url" in data:
                import re

                match = re.search(r"/patent/([^/]+)/", data["google_patents_url"])
                if match:
                    patent_number = match.group(1)

            if patent_number:
                samples_with_links.append(
                    (key, patent_number, data["description_link"])
                )

    print(f"Description_linkê°€ ìˆëŠ” ìƒ˜í”Œ: {len(samples_with_links)}ê°œ")

    if not samples_with_links:
        print("âŒ Description_linkê°€ ìˆëŠ” ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì²« ë²ˆì§¸ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸
    sample_key, patent_number, description_link = samples_with_links[0]
    print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {patent_number}")
    print(f"Description link: {description_link}")

    # 2. ì‹¤ì œ ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜í–‰
    print(f"\nğŸ“¡ ì›¹ ìŠ¤í¬ë˜í•‘ ì¤‘...")
    scraper = GooglePatentsDescriptionScraper()

    try:
        # ë‹¨ì¼ URL ìŠ¤í¬ë˜í•‘
        scraping_result = scraper.scrape_patent_description(description_link)

        if not scraping_result.success:
            print(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {scraping_result.error_message}")
            return

        description = scraping_result.description

        print(f"âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(description):,} ë¬¸ì")
        print(f"ë¯¸ë¦¬ë³´ê¸°: {description[:200]}...")

    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        return

    # 3. ìºì‹œ ë°ì´í„°ë¥¼ SerpAPI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    cache_item = cache_data[sample_key]["data"]

    converted_data = {
        "title": cache_item.get("title", ""),
        "abstract": cache_item.get("abstract", ""),
        "claims": cache_item.get("claims", []),
        "description": description,  # ìŠ¤í¬ë˜í•‘ëœ ì„¤ëª… ì‚¬ìš©
        "description_link": cache_item.get("description_link", ""),
        "filing_date": cache_item.get("application_date", ""),
        "publication_date": cache_item.get("publication_date", ""),
        "application_date": cache_item.get("application_date", ""),
        "status": cache_item.get("status", ""),
        "inventor": cache_item.get("inventor", []),
        "assignee": cache_item.get("assignee", []),
        "classifications": cache_item.get("classifications", []),
        "citations": cache_item.get("citations", {}),
        "google_patents_url": cache_item.get("google_patents_url", ""),
        "search_timestamp": cache_item.get("search_timestamp", ""),
        "raw_data": cache_item.get("raw_data", {}),
    }

    search_results = {"results": {patent_number: converted_data}}

    # 4. ë°ì´í„° ì²˜ë¦¬ ë° ì²­í‚¹
    print(f"\nğŸ”ª í…ìŠ¤íŠ¸ ì²­í‚¹ ì²˜ë¦¬...")
    processor = PatentDataProcessor(chunk_size=1200, chunk_overlap=200)

    try:
        patents, chunks = processor.process_search_results(search_results)

        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  íŠ¹í—ˆ ìˆ˜: {len(patents)}")
        print(f"  ì²­í¬ ìˆ˜: {len(chunks)}")

        if patents:
            patent = patents[0]
            print(f"\nğŸ“Š íŠ¹í—ˆ ì •ë³´:")
            print(f"  ë²ˆí˜¸: {patent.patent_number}")
            print(f"  ì œëª©: {patent.title}")
            print(f"  ì´ˆë¡ ê¸¸ì´: {len(patent.abstract):,} ë¬¸ì")
            print(f"  ì²­êµ¬í•­ ìˆ˜: {len(patent.claims)}")
            print(f"  ì„¤ëª… ê¸¸ì´: {len(patent.description):,} ë¬¸ì")
            print(f"  ì™„ì „ì„±: {patent.is_complete}")

            print(f"\nğŸ“¦ ì²­í¬ ë¶„ì„:")
            chunk_types = {}
            for chunk in chunks:
                chunk_type = chunk.section  # section í•„ë“œ ì§ì ‘ ì‚¬ìš©
                chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1

            for chunk_type, count in sorted(chunk_types.items()):
                print(f"  {chunk_type}: {count}ê°œ")

            # ì„¤ëª… ì²­í¬ë“¤ ë¯¸ë¦¬ë³´ê¸°
            description_chunks = [
                c
                for c in chunks
                if c.section == "description"  # section í•„ë“œ ì§ì ‘ ì‚¬ìš©
            ]
            if description_chunks:
                print(f"\nğŸ“ ì„¤ëª… ì²­í¬ ë¯¸ë¦¬ë³´ê¸° (ì´ {len(description_chunks)}ê°œ):")
                for i, chunk in enumerate(description_chunks[:3]):  # ì²˜ìŒ 3ê°œë§Œ
                    print(f"  ì²­í¬ {i+1}: {chunk.content[:100]}...")
                    print(f"    ê¸¸ì´: {len(chunk.content)} ë¬¸ì")
                    print(f"    ì²­í¬ ID: {chunk.chunk_id}")

            # ê²°ê³¼ ì €ì¥
            structured_data = processor.combine_to_structured_format(patents, chunks)

            with open(
                "description_chunking_test_result.json", "w", encoding="utf-8"
            ) as f:
                json.dump(structured_data, f, ensure_ascii=False, indent=2)

            print(
                f"\nğŸ’¾ ê²°ê³¼ê°€ description_chunking_test_result.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

            return True

    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_description_scraping_and_chunking()
