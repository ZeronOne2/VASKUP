#!/usr/bin/env python3
"""Vector Store í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import json
import logging
import os
import sys
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.vector_store.embedding_manager import EmbeddingManager
from src.vector_store.patent_vector_store import PatentVectorStore
from src.patent_search.patent_parser import DocumentChunk


def test_vector_store():
    """Vector Store í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸš€ Vector Store í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)

    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print("\n1ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ")
    try:
        # ì´ì „ì— ìƒì„±í•œ ì²­í‚¹ ê²°ê³¼ ë¡œë“œ
        with open("description_chunking_test_result.json", "r", encoding="utf-8") as f:
            test_data = json.load(f)

        # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
        patent = test_data["patents"][0]  # patents ë°°ì—´ì˜ ì²« ë²ˆì§¸ íŠ¹í—ˆ

        # ê° ì„¹ì…˜ì˜ chunksë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•˜ì—¬ DocumentChunk ê°ì²´ë¡œ ë³€í™˜
        chunks_data = []

        # Title chunk ì¶”ê°€ (ë‹¨ì¼ ë¬¸ìì—´)
        if patent.get("title"):
            title_chunk = DocumentChunk(
                patent_number=patent["patent_number"],
                section="title",
                chunk_index=0,
                content=patent["title"],
                metadata={
                    "patent_number": patent["patent_number"],
                    "section": "title",
                    "chunk_index": 0,
                },
            )
            chunks_data.append(title_chunk)

        # Abstract chunk ì¶”ê°€ (ë‹¨ì¼ ë¬¸ìì—´)
        if patent.get("abstract"):
            abstract_chunk = DocumentChunk(
                patent_number=patent["patent_number"],
                section="abstract",
                chunk_index=0,
                content=patent["abstract"],
                metadata={
                    "patent_number": patent["patent_number"],
                    "section": "abstract",
                    "chunk_index": 0,
                },
            )
            chunks_data.append(abstract_chunk)

        # Claims chunks ì¶”ê°€ (ë¬¸ìì—´ ë°°ì—´)
        if patent.get("claims"):
            for i, claim in enumerate(patent["claims"]):
                claim_chunk = DocumentChunk(
                    patent_number=patent["patent_number"],
                    section="claims",
                    chunk_index=i,
                    content=claim,
                    metadata={
                        "patent_number": patent["patent_number"],
                        "section": "claims",
                        "chunk_index": i,
                    },
                )
                chunks_data.append(claim_chunk)

        # Description chunks ì¶”ê°€ (ë¬¸ìì—´ ë°°ì—´)
        if patent.get("description_chunks"):
            for i, chunk_text in enumerate(patent["description_chunks"]):
                desc_chunk = DocumentChunk(
                    patent_number=patent["patent_number"],
                    section="description",
                    chunk_index=i,
                    content=chunk_text,
                    metadata={
                        "patent_number": patent["patent_number"],
                        "section": "description",
                        "chunk_index": i,
                    },
                )
                chunks_data.append(desc_chunk)

        print(f"  âœ… íŠ¹í—ˆ ë¡œë“œ: {patent['patent_number']}")
        print(f"  âœ… ì´ ì²­í¬ ìˆ˜: {len(chunks_data)}ê°œ")
        print(f"     - Title: {1 if patent.get('title') else 0}")
        print(f"     - Abstract: {1 if patent.get('abstract') else 0}")
        print(f"     - Claims: {len(patent.get('claims', []))}")
        print(f"     - Description: {len(patent.get('description_chunks', []))}")

    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. Embedding Manager ì´ˆê¸°í™”
    print("\n2ï¸âƒ£ Embedding Manager ì´ˆê¸°í™”")
    try:
        embedding_manager = EmbeddingManager()
        print("  âœ… EmbeddingManager ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  ğŸ“Š ëª¨ë¸: {embedding_manager.model}")
        print(f"  ğŸ“Š ì°¨ì›: {embedding_manager.dimensions}")
    except Exception as e:
        print(f"  âŒ EmbeddingManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # 3. Vector Store ì´ˆê¸°í™”
    print("\n3ï¸âƒ£ Vector Store ì´ˆê¸°í™”")
    try:
        vector_store = PatentVectorStore(
            embedding_manager=embedding_manager,
            collection_name="test_patents",
            persist_directory="./data/chroma_test",
            reset_collection=True,  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ì¡´ ë°ì´í„° ë¦¬ì…‹
        )
        print("  âœ… PatentVectorStore ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  ğŸ“Š ì»¬ë ‰ì…˜: {vector_store.collection_name}")
        print(f"  ğŸ“Š ì €ì¥ ê²½ë¡œ: {vector_store.persist_directory}")
    except Exception as e:
        print(f"  âŒ PatentVectorStore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # 4. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸ (ìƒ˜í”Œ 5ê°œ)
    print("\n4ï¸âƒ£ ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸")
    try:
        sample_chunks = chunks_data[:5]  # ì²˜ìŒ 5ê°œ ì²­í¬ë§Œ í…ŒìŠ¤íŠ¸

        for i, chunk in enumerate(sample_chunks):
            print(f"  í…ŒìŠ¤íŠ¸ {i+1}: {chunk.metadata['section']} ì„¹ì…˜")
            print(f"    ë‚´ìš© ê¸¸ì´: {len(chunk.content)} ë¬¸ì")
            print(f"    ì²­í¬ ID: {chunk.chunk_id}")

        # ì„ë² ë”© ìƒì„±
        embedding_results = embedding_manager.create_embeddings_batch(
            [chunk.content for chunk in sample_chunks]
        )
        embeddings = [result.embedding for result in embedding_results]

        print(f"  âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ")
        print(f"  ğŸ“Š ì„ë² ë”© ì°¨ì›: {len(embeddings[0])}")
        print(f"  ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {embedding_manager.total_tokens_used}")

    except Exception as e:
        print(f"  âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return

    # 5. Vector Storeì— ì²­í¬ ì €ì¥
    print("\n5ï¸âƒ£ Vector Storeì— ì²­í¬ ì €ì¥")
    try:
        # ëª¨ë“  ì²­í¬ë¥¼ ë°°ì¹˜ë¡œ ì €ì¥
        success_count, error_count = vector_store.add_document_chunks_batch(
            chunks_data[:10]
        )  # ì²˜ìŒ 10ê°œë§Œ í…ŒìŠ¤íŠ¸

        print(f"  âœ… ì²­í¬ ì €ì¥ ì™„ë£Œ: {success_count + error_count}ê°œ")
        print(f"  ğŸ“Š ì„±ê³µ: {success_count}")
        print(f"  ğŸ“Š ì‹¤íŒ¨: {error_count}")

    except Exception as e:
        print(f"  âŒ ì²­í¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        return

    # 6. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n6ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    try:
        test_queries = [
            "machine learning storage system",
            "hardware component monitoring",
            "data storage and retrieval",
            "flash memory technology",
            "storage cluster architecture",
        ]

        for i, query in enumerate(test_queries):
            print(f"\n  ê²€ìƒ‰ {i+1}: '{query}'")

            search_results = vector_store.search_similar(
                query=query, n_results=3, include_distances=True
            )
            results = search_results.get("results", [])

            if results:
                print(f"    ì°¾ì€ ê²°ê³¼: {len(results)}ê°œ")
                for j, result in enumerate(results):
                    distance = result.get("distance", "N/A")
                    content_preview = (
                        result["content"][:100] + "..."
                        if len(result["content"]) > 100
                        else result["content"]
                    )
                    section = result["metadata"].get("section", "unknown")
                    print(
                        f"      {j+1}. ê±°ë¦¬: {distance:.4f} | {section} | {content_preview}"
                    )
            else:
                print("    ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

    except Exception as e:
        print(f"  âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return

    # 7. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n7ï¸âƒ£ í†µê³„ ì •ë³´")
    try:
        stats = vector_store.get_stats()
        print(f"  ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_chunks', 0)}")
        print(f"  ğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´: {stats.get('collection_info', {})}")

        embedding_stats = embedding_manager.get_stats()
        print(f"  ğŸ“Š ì´ í† í° ì‚¬ìš©ëŸ‰: {embedding_stats.get('total_tokens', 0)}")
        print(f"  ğŸ“Š ì´ API í˜¸ì¶œ ìˆ˜: {embedding_stats.get('total_calls', 0)}")
        if embedding_stats.get("total_calls", 0) > 0:
            print(
                f"  ğŸ“Š í‰ê·  í† í°/í˜¸ì¶œ: {embedding_stats.get('total_tokens', 0) / embedding_stats.get('total_calls', 1):.1f}"
            )

    except Exception as e:
        print(f"  âŒ í†µê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    print("\n" + "=" * 80)
    print("ğŸ‰ Vector Store í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    test_vector_store()
