#!/usr/bin/env python3
"""
Vector Store í…ŒìŠ¤íŠ¸ìš© Streamlit ì›¹ì•±
Task 1-6ê¹Œì§€ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import streamlit as st
import os
import sys
import json
import time
from typing import List, Dict, Any

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.patent_search.serp_client import SerpPatentClient
from src.patent_search.description_scraper import GooglePatentsDescriptionScraper
from src.patent_search.patent_parser import PatentParser, PatentDataProcessor
from src.vector_store.patent_vector_store import PatentVectorStore
from src.vector_store.embedding_manager import EmbeddingManager

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŠ¹í—ˆ Vector Store í…ŒìŠ¤íŠ¸",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "search_results" not in st.session_state:
        st.session_state.search_results = []
    if "processed_patents" not in st.session_state:
        st.session_state.processed_patents = []


@st.cache_resource
def load_vector_store():
    """Vector Store ì´ˆê¸°í™” ë° ë¡œë“œ"""
    try:
        vector_store = PatentVectorStore(
            persist_directory="./streamlit_chroma_db",
            collection_name="patent_test",
            reset_collection=False,  # ê¸°ì¡´ ë°ì´í„° ìœ ì§€
            enable_preprocessing=True,
            enable_performance_monitoring=True,
        )
        return vector_store
    except Exception as e:
        st.error(f"Vector Store ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def search_and_process_patents(query: str, num_results: int = 5):
    """íŠ¹í—ˆ ê²€ìƒ‰ ë° ì²˜ë¦¬"""
    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        # 1. SERP API ê²€ìƒ‰
        status_text.text("ğŸ” íŠ¹í—ˆ ê²€ìƒ‰ ì¤‘...")
        progress_bar.progress(20)

        serp_client = SerpPatentClient()
        search_results = serp_client.search_patents(query, num_results=num_results)

        if not search_results or "organic_results" not in search_results:
            st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # 2. ì›¹ ìŠ¤í¬ë˜í•‘
        status_text.text("ğŸ“„ íŠ¹í—ˆ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        progress_bar.progress(40)

        scraper = GooglePatentsDescriptionScraper()
        scraping_results = scraper.scrape_batch_descriptions(
            search_results["organic_results"], max_workers=2
        )

        # 3. ë°ì´í„° ì²˜ë¦¬ ë° ì²­í‚¹
        status_text.text("âš™ï¸ ë°ì´í„° ì²˜ë¦¬ ë° ì²­í‚¹ ì¤‘...")
        progress_bar.progress(60)

        processor = PatentDataProcessor()
        patents, chunks = processor.process_search_results(
            search_results, scraping_results
        )

        progress_bar.progress(100)
        status_text.text("âœ… ì²˜ë¦¬ ì™„ë£Œ!")

        return patents, chunks

    except Exception as e:
        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], []


def main():
    """ë©”ì¸ ì•±"""
    init_session_state()

    st.title("ğŸ”¬ íŠ¹í—ˆ Vector Store í…ŒìŠ¤íŠ¸")
    st.markdown("Task 1-6ê¹Œì§€ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")

    # Vector Store ì´ˆê¸°í™”
    if st.sidebar.button("ğŸš€ Vector Store ì´ˆê¸°í™”"):
        st.session_state.vector_store = load_vector_store()
        if st.session_state.vector_store:
            st.sidebar.success("Vector Store ì´ˆê¸°í™” ì™„ë£Œ!")
        else:
            st.sidebar.error("Vector Store ì´ˆê¸°í™” ì‹¤íŒ¨!")

    # Vector Store ìƒíƒœ í‘œì‹œ
    if st.session_state.vector_store:
        st.sidebar.success("âœ… Vector Store ì¤€ë¹„ë¨")

        # Vector Store í†µê³„
        try:
            stats = st.session_state.vector_store.get_stats()
            st.sidebar.metric("ì €ì¥ëœ ì²­í¬ ìˆ˜", stats.get("total_chunks", 0))
            st.sidebar.metric("ê³ ìœ  íŠ¹í—ˆ ìˆ˜", stats.get("unique_patents", 0))
        except:
            pass
    else:
        st.sidebar.warning("âŒ Vector Store ë¯¸ì´ˆê¸°í™”")

    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(
        ["ğŸ” íŠ¹í—ˆ ê²€ìƒ‰ & ì €ì¥", "ğŸ¯ ìœ ì‚¬ë„ ê²€ìƒ‰", "ğŸ“Š Vector Store ê´€ë¦¬"]
    )

    with tab1:
        st.header("íŠ¹í—ˆ ê²€ìƒ‰ ë° Vector Store ì €ì¥")

        col1, col2 = st.columns([3, 1])
        with col1:
            search_query = st.text_input(
                "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                placeholder="ì˜ˆ: artificial intelligence, machine learning",
                help="ì˜ì–´ë¡œ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )
        with col2:
            num_results = st.selectbox("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜:", [3, 5, 10], index=1)

        if st.button(
            "ğŸ” ê²€ìƒ‰ ë° ì²˜ë¦¬ ì‹œì‘", disabled=not st.session_state.vector_store
        ):
            if search_query:
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    patents, chunks = search_and_process_patents(
                        search_query, num_results
                    )

                    if patents and chunks:
                        st.success(
                            f"âœ… {len(patents)}ê°œ íŠ¹í—ˆ, {len(chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ!"
                        )

                        # Vector Storeì— ì €ì¥
                        st.info("Vector Storeì— ì €ì¥ ì¤‘...")
                        success_count, error_count = (
                            st.session_state.vector_store.add_document_chunks_batch(
                                chunks
                            )
                        )

                        if success_count > 0:
                            st.success(
                                f"ğŸ‰ {success_count}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ! (ì˜¤ë¥˜: {error_count}ê°œ)"
                            )
                            st.session_state.processed_patents.extend(patents)
                        else:
                            st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨! ì˜¤ë¥˜: {error_count}ê°œ")

                        # ê²°ê³¼ í‘œì‹œ
                        with st.expander("ğŸ“‹ ì²˜ë¦¬ëœ íŠ¹í—ˆ ëª©ë¡", expanded=True):
                            for i, patent in enumerate(patents, 1):
                                st.markdown(f"**{i}. {patent.title}**")
                                st.markdown(f"íŠ¹í—ˆë²ˆí˜¸: `{patent.patent_number}`")
                                st.markdown(f"ì¶œì›ì¼: {patent.filing_date or 'N/A'}")
                                st.markdown(
                                    f"ì²­í¬ ìˆ˜: {len([c for c in chunks if c.patent_number == patent.patent_number])}"
                                )
                                st.markdown("---")
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with tab2:
        st.header("Vector Store ìœ ì‚¬ë„ ê²€ìƒ‰")

        if not st.session_state.vector_store:
            st.warning("ë¨¼ì € Vector Storeë¥¼ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
            return

        col1, col2 = st.columns([3, 1])
        with col1:
            similarity_query = st.text_input(
                "ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                placeholder="ì˜ˆ: deep learning algorithm, neural network",
                help="ì €ì¥ëœ íŠ¹í—ˆ ì²­í¬ì—ì„œ ìœ ì‚¬í•œ ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤.",
            )
        with col2:
            search_limit = st.selectbox("ê²°ê³¼ ê°œìˆ˜:", [5, 10, 20], index=1)

        if st.button("ğŸ¯ ìœ ì‚¬ë„ ê²€ìƒ‰"):
            if similarity_query:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    start_time = time.time()
                    results = st.session_state.vector_store.search_similar(
                        similarity_query, n_results=search_limit, include_distances=True
                    )
                    search_time = time.time() - start_time

                st.success(
                    f"âœ… ê²€ìƒ‰ ì™„ë£Œ! ({search_time:.3f}ì´ˆ, {results['total_results']}ê°œ ê²°ê³¼)"
                )

                if results["results"]:
                    for i, result in enumerate(results["results"], 1):
                        with st.expander(
                            f"ğŸ“„ ê²°ê³¼ {i} (ìœ ì‚¬ë„: {result.get('similarity', 0):.3f})",
                            expanded=i <= 3,
                        ):
                            st.markdown(f"**ì²­í¬ ID:** `{result['chunk_id']}`")
                            st.markdown(
                                f"**íŠ¹í—ˆë²ˆí˜¸:** {result['metadata'].get('patent_number', 'N/A')}"
                            )
                            st.markdown(
                                f"**ì„¹ì…˜:** {result['metadata'].get('section', 'N/A')}"
                            )
                            st.markdown(
                                f"**ê±°ë¦¬:** {result.get('distance', 'N/A'):.4f}"
                            )
                            st.markdown("**ë‚´ìš©:**")
                            st.markdown(f"```\n{result['content'][:500]}...\n```")
                else:
                    st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with tab3:
        st.header("Vector Store ê´€ë¦¬")

        if not st.session_state.vector_store:
            st.warning("ë¨¼ì € Vector Storeë¥¼ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
            return

        # í†µê³„ ì •ë³´
        try:
            stats = st.session_state.vector_store.get_stats()

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì²­í¬ ìˆ˜", stats.get("total_chunks", 0))
            with col2:
                st.metric("ê³ ìœ  íŠ¹í—ˆ ìˆ˜", stats.get("unique_patents", 0))
            with col3:
                st.metric(
                    "í‰ê·  ì²­í¬ ê¸¸ì´", f"{stats.get('avg_chunk_length', 0):.0f} ë¬¸ì"
                )

        except Exception as e:
            st.error(f"í†µê³„ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        if (
            hasattr(st.session_state.vector_store, "performance_monitor")
            and st.session_state.vector_store.performance_monitor
        ):
            st.subheader("ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")

            monitor = st.session_state.vector_store.performance_monitor
            overall_stats = monitor.get_overall_stats()

            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ ì‘ì—… ìˆ˜", overall_stats["total_operations"])
                st.metric("ì„±ê³µë¥ ", f"{overall_stats['success_rate']:.1%}")
            with col2:
                st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{overall_stats['avg_duration']:.3f}ì´ˆ")

            # ì‘ì—…ë³„ ì„±ëŠ¥
            if overall_stats["operations_by_type"]:
                st.subheader("ì‘ì—…ë³„ ì„±ëŠ¥")
                for op_name, op_stats in overall_stats["operations_by_type"].items():
                    st.markdown(
                        f"**{op_name}**: {op_stats['count']}íšŒ, í‰ê·  {op_stats['avg_duration']:.3f}ì´ˆ"
                    )

            # ê¶Œì¥ì‚¬í•­
            recommendations = monitor.generate_recommendations()
            if recommendations:
                st.subheader("ğŸ”§ ìµœì í™” ê¶Œì¥ì‚¬í•­")
                for i, rec in enumerate(recommendations, 1):
                    st.markdown(f"{i}. {rec}")

        # ê´€ë¦¬ ì‘ì—…
        st.subheader("ğŸ› ï¸ ê´€ë¦¬ ì‘ì—…")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ Vector Store ì´ˆê¸°í™”", type="secondary"):
                if st.session_state.vector_store:
                    st.session_state.vector_store.reset_collection()
                    st.success("Vector Storeê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()

        with col2:
            if st.button("ğŸ’¾ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ", type="secondary"):
                st.info("ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
