import sys
import os

sys.path.append("src")

import json
from patent_search.patent_parser import (
    PatentDataProcessor,
    Patent,
    DocumentChunk,
    format_patent_id,
    parse_description,
)
from patent_search.serp_client import SerpPatentClient
from patent_search.description_scraper import GooglePatentsDescriptionScraper

print("ğŸ” íŠ¹í—ˆ ë°ì´í„° ì²˜ë¦¬ ë° ì²­í‚¹ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
print("=" * 60)


def test_format_patent_id():
    """íŠ¹í—ˆ ID ë³€í™˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    print("\n1ï¸âƒ£ íŠ¹í—ˆ ID ë³€í™˜ í…ŒìŠ¤íŠ¸")

    test_cases = [
        "US11734097B1",
        "US20210390793A1",
        "patent/US11630280B2/en",  # ì´ë¯¸ ë³€í™˜ëœ í˜•ì‹
        "US 11630282 B2",  # ê³µë°± í¬í•¨
        "",  # ë¹ˆ ë¬¸ìì—´
    ]

    for patent_num in test_cases:
        formatted = format_patent_id(patent_num)
        print(f"  '{patent_num}' -> '{formatted}'")


def test_parse_description():
    """HTML ì„¤ëª… íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    print("\n2ï¸âƒ£ HTML ì„¤ëª… íŒŒì‹± í…ŒìŠ¤íŠ¸")

    # ìƒ˜í”Œ HTML (ì‹¤ì œì™€ ìœ ì‚¬í•œ êµ¬ì¡°)
    html_content = """
    <div>
        <span class="google-src-text">ì›ë³¸ í…ìŠ¤íŠ¸ (ì œê±° ëŒ€ìƒ)</span>
        <p>This is the English translation of the patent description.</p>
        <span class="google-src-text">ë” ë§ì€ ì›ë³¸ í…ìŠ¤íŠ¸</span>
        <p>Multiple paragraphs with important technical details.</p>
    </div>
    """

    parsed = parse_description(html_content)
    print(f"  íŒŒì‹± ê²°ê³¼: '{parsed}'")
    print(f"  ê¸¸ì´: {len(parsed)} ë¬¸ì")


def test_patent_class():
    """Patent í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\n3ï¸âƒ£ Patent í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸")

    # ê¸°ë³¸ Patent ê°ì²´ ìƒì„±
    patent = Patent(
        patent_number="US11734097B1",
        patent_id="",  # __post_init__ì—ì„œ ìë™ ìƒì„±ë¨
        title="Test Patent Title",
        abstract="This is a test patent abstract with technical details.",
        claims=["First claim of the patent", "Second claim of the patent"],
        description="Original description from SERP API",
        filing_date="2021-01-27",
        publication_date="2023-08-22",
    )

    print(f"  íŠ¹í—ˆë²ˆí˜¸: {patent.patent_number}")
    print(f"  ìë™ ìƒì„±ëœ patent_id: {patent.patent_id}")
    print(f"  ì™„ì „ì„± ê²€ì‚¬: {patent.is_complete}")
    print(f"  íš¨ê³¼ì ì¸ ì„¤ëª… ê¸¸ì´: {len(patent.effective_description)} ë¬¸ì")
    print(f"  íš¨ê³¼ì ì¸ ì²­êµ¬í•­ ìˆ˜: {len(patent.effective_claims)}ê°œ")

    # ì›¹ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
    patent.scraped_description = (
        "Enhanced description from web scraping with more details"
    )
    patent.scraping_success = True

    print(f"  ìŠ¤í¬ë˜í•‘ í›„ íš¨ê³¼ì ì¸ ì„¤ëª…: {len(patent.effective_description)} ë¬¸ì")
    print(f"  ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {patent.scraping_success}")


def test_patent_chunker():
    """íŠ¹í—ˆ ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
    print("\n4ï¸âƒ£ íŠ¹í—ˆ ì²­í‚¹ í…ŒìŠ¤íŠ¸")

    # í…ŒìŠ¤íŠ¸ìš© ê¸´ ì„¤ëª… ìƒì„±
    long_description = " ".join(
        [
            f"This is paragraph {i} of a very long patent description."
            for i in range(1, 100)  # ê¸´ í…ìŠ¤íŠ¸ ìƒì„±
        ]
    )

    patent = Patent(
        patent_number="US11734097B1",
        patent_id="patent/US11734097B1/en",
        title="Advanced Machine Learning System for Patent Analysis",
        abstract="A comprehensive system for analyzing patents using advanced ML techniques.",
        claims=[
            "A method for processing patent data comprising steps of data collection and analysis",
            "The method of claim 1, wherein the analysis includes natural language processing",
            "A system implementing the method of claim 1 with distributed computing resources",
        ],
        description=long_description,
        filing_date="2021-01-27",
        publication_date="2023-08-22",
    )

    # ì²­í‚¹ ìˆ˜í–‰
    from patent_search.patent_parser import PatentChunker

    chunker = PatentChunker(chunk_size=500, chunk_overlap=100)  # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ í¬ê¸°
    chunks = chunker.chunk_patent(patent)

    print(f"  ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")

    # ì„¹ì…˜ë³„ ì²­í¬ ë¶„í¬
    distribution = {}
    for chunk in chunks:
        section = chunk.section
        distribution[section] = distribution.get(section, 0) + 1

    print("  ì„¹ì…˜ë³„ ì²­í¬ ë¶„í¬:")
    for section, count in distribution.items():
        print(f"    {section}: {count}ê°œ")

    # ê° ì²­í¬ ë¯¸ë¦¬ë³´ê¸°
    print("\n  ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:")
    for i, chunk in enumerate(chunks[:5]):  # ì²˜ìŒ 5ê°œë§Œ
        preview = (
            chunk.content[:50] + "..." if len(chunk.content) > 50 else chunk.content
        )
        print(f"    ì²­í¬ {i+1} ({chunk.section}): {preview}")
        print(f"      ì²­í¬ ID: {chunk.chunk_id}")


def test_real_data_processing():
    """ì‹¤ì œ ë°ì´í„°ë¡œ ì¢…í•© í…ŒìŠ¤íŠ¸"""
    print("\n5ï¸âƒ£ ì‹¤ì œ ë°ì´í„° ì¢…í•© ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")

    # ìºì‹œëœ ë°ì´í„° ë¡œë“œ
    try:
        with open("src/cache/patent_cache.json", "r", encoding="utf-8") as f:
            cache_data = json.load(f)

        print(f"  ìºì‹œëœ íŠ¹í—ˆ ìˆ˜: {len(cache_data)}ê°œ")

        # ì²˜ìŒ 3ê°œ íŠ¹í—ˆë¡œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ìºì‹œ êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜)
        test_patents = {}
        count = 0
        for cache_key, cache_item in cache_data.items():
            if count >= 3:
                break

            # ìºì‹œ êµ¬ì¡°: cache_item['data']ì— ì‹¤ì œ íŠ¹í—ˆ ë°ì´í„°ê°€ ìˆìŒ
            patent_data = cache_item.get("data", {})

            # íŠ¹í—ˆë²ˆí˜¸ ì¶”ì¶œ (publication_numberë‚˜ google_patents_urlì—ì„œ)
            patent_number = None
            if (
                "raw_data" in patent_data
                and "publication_number" in patent_data["raw_data"]
            ):
                patent_number = patent_data["raw_data"]["publication_number"]
            elif "google_patents_url" in patent_data:
                # URLì—ì„œ íŠ¹í—ˆë²ˆí˜¸ ì¶”ì¶œ: https://patents.google.com/patent/US11734097B1/en
                import re

                match = re.search(
                    r"/patent/([^/]+)/", patent_data["google_patents_url"]
                )
                if match:
                    patent_number = match.group(1)

            if patent_number:
                # ìºì‹œ êµ¬ì¡°ë¥¼ SerpAPI ê²°ê³¼ êµ¬ì¡°ë¡œ ë³€í™˜
                converted_data = {
                    "title": patent_data.get("title", ""),
                    "abstract": patent_data.get("abstract", ""),
                    "claims": patent_data.get("claims", []),
                    "description": "",  # ìºì‹œì—ëŠ” descriptionì´ ì§ì ‘ ì—†ìŒ
                    "description_link": patent_data.get("description_link", ""),
                    "filing_date": patent_data.get(
                        "application_date", ""
                    ),  # filing_date -> application_date ë§¤í•‘
                    "publication_date": patent_data.get("publication_date", ""),
                    "application_date": patent_data.get("application_date", ""),
                    "status": patent_data.get("status", ""),
                    "inventor": patent_data.get("inventor", []),
                    "assignee": patent_data.get("assignee", []),
                    "classifications": patent_data.get("classifications", []),
                    "citations": patent_data.get("citations", {}),
                    "google_patents_url": patent_data.get("google_patents_url", ""),
                    "search_timestamp": patent_data.get("search_timestamp", ""),
                    "raw_data": patent_data.get("raw_data", {}),
                }

                test_patents[patent_number] = converted_data
                count += 1

        if not test_patents:
            print("  ë³€í™˜ ê°€ëŠ¥í•œ íŠ¹í—ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        search_results = {"results": test_patents}

        print(f"  ë³€í™˜ëœ íŠ¹í—ˆ ìˆ˜: {len(test_patents)}ê°œ")
        for patent_num in test_patents.keys():
            print(f"    - {patent_num}")

        # ë°ì´í„° ì²˜ë¦¬ê¸° ìƒì„±
        processor = PatentDataProcessor(chunk_size=800, chunk_overlap=150)

        # ì²˜ë¦¬ ìˆ˜í–‰
        patents, chunks = processor.process_search_results(search_results)

        print(f"  ì²˜ë¦¬ëœ íŠ¹í—ˆ ìˆ˜: {len(patents)}ê°œ")
        print(f"  ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")

        if len(chunks) == 0:
            print("  âš ï¸ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„° ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤:")
            for patent in patents:
                print(f"    íŠ¹í—ˆ {patent.patent_number}:")
                print(f"      ì œëª© ê¸¸ì´: {len(patent.title)} ë¬¸ì")
                print(f"      ì´ˆë¡ ê¸¸ì´: {len(patent.abstract)} ë¬¸ì")
                print(f"      ì²­êµ¬í•­ ìˆ˜: {len(patent.claims)}ê°œ")
                print(f"      ì„¤ëª… ê¸¸ì´: {len(patent.description)} ë¬¸ì")
                print(
                    f"      ìŠ¤í¬ë˜í•‘ëœ ì„¤ëª… ê¸¸ì´: {len(patent.scraped_description)} ë¬¸ì"
                )
                print(f"      ì™„ì „ì„±: {patent.is_complete}")

        # êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
        structured_data = processor.combine_to_structured_format(patents, chunks)

        print(f"  ë©”íƒ€ë°ì´í„°:")
        print(f"    ì „ì²´ íŠ¹í—ˆ: {structured_data['metadata']['total_patents']}ê°œ")
        print(f"    ì „ì²´ ì²­í¬: {structured_data['metadata']['total_chunks']}ê°œ")
        print(f"    ì²˜ë¦¬ ì‹œê°„: {structured_data['metadata']['processing_timestamp']}")
        print(f"    ì²­í¬ ë¶„í¬: {structured_data['metadata']['chunk_distribution']}")

        # ìƒ˜í”Œ íŠ¹í—ˆ ìƒì„¸ ì •ë³´
        if patents:
            sample_patent = patents[0]
            print(f"\n  ìƒ˜í”Œ íŠ¹í—ˆ ({sample_patent.patent_number}):")
            print(f"    ì œëª©: {sample_patent.title[:50]}...")
            print(f"    ì´ˆë¡: {sample_patent.abstract[:50]}...")
            print(f"    ì²­êµ¬í•­ ìˆ˜: {len(sample_patent.effective_claims)}ê°œ")
            print(f"    ì„¤ëª… ê¸¸ì´: {len(sample_patent.effective_description):,} ë¬¸ì")
            print(f"    ì„¤ëª… ì²­í¬ ìˆ˜: {len(sample_patent.description_chunks)}ê°œ")
            print(f"    ì™„ì „ì„±: {sample_patent.is_complete}")

        return structured_data

    except FileNotFoundError:
        print("  ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"  ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        return None


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        test_format_patent_id()
        test_parse_description()
        test_patent_class()
        test_patent_chunker()
        structured_data = test_real_data_processing()

        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì )
        if structured_data:
            output_file = "test_patent_processing_result.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(structured_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
