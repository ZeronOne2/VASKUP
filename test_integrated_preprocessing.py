#!/usr/bin/env python3
"""ì „ì²˜ë¦¬ í†µí•© Vector Store í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import json
import logging
import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.vector_store.embedding_manager import EmbeddingManager
from src.vector_store.patent_vector_store import PatentVectorStore
from src.patent_search.patent_parser import DocumentChunk


def test_integrated_preprocessing():
    """ì „ì²˜ë¦¬ í†µí•© Vector Store í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ”§ ì „ì²˜ë¦¬ í†µí•© Vector Store í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)

    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print("\n1ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ")
    try:
        with open("description_chunking_test_result.json", "r", encoding="utf-8") as f:
            test_data = json.load(f)

        patent = test_data["patents"][0]

        # ìƒ˜í”Œ ì²­í¬ ìƒì„± (HTML íƒœê·¸ì™€ íŠ¹ìˆ˜ ë¬¸ìê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¡œ ì‹œë®¬ë ˆì´ì…˜)
        sample_chunks = []

        # Title chunk (HTML íƒœê·¸ ì¶”ê°€)
        if patent.get("title"):
            title_chunk = DocumentChunk(
                patent_number=patent["patent_number"],
                section="title",
                chunk_index=0,
                content=f"<b>{patent['title']}</b> with <span>HTML tags</span>",
                metadata={
                    "patent_number": patent["patent_number"],
                    "section": "title",
                    "chunk_index": 0,
                },
            )
            sample_chunks.append(title_chunk)

        # Description chunks (ë„ë©´ ì°¸ì¡° ì¶”ê°€)
        if patent.get("description_chunks"):
            for i, chunk_text in enumerate(patent["description_chunks"][:3]):
                # ë„ë©´ ì°¸ì¡°ì™€ ì°¸ì¡° ë²ˆí˜¸ ì¶”ê°€
                modified_text = f"{chunk_text} See FIG. {i+1}A for details. Component (100) is shown."
                desc_chunk = DocumentChunk(
                    patent_number=patent["patent_number"],
                    section="description",
                    chunk_index=i,
                    content=modified_text,
                    metadata={
                        "patent_number": patent["patent_number"],
                        "section": "description",
                        "chunk_index": i,
                    },
                )
                sample_chunks.append(desc_chunk)

        print(f"  âœ… í…ŒìŠ¤íŠ¸ ì²­í¬ ìƒì„±: {len(sample_chunks)}ê°œ")

        # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
        total_original_length = sum(len(chunk.content) for chunk in sample_chunks)
        print(f"  ğŸ“Š ì´ ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {total_original_length:,} ë¬¸ì")

    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. Embedding Manager ì´ˆê¸°í™”
    print("\n2ï¸âƒ£ Embedding Manager ì´ˆê¸°í™”")
    try:
        embedding_manager = EmbeddingManager()
        print("  âœ… EmbeddingManager ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âŒ EmbeddingManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # 3. ì „ì²˜ë¦¬ ë¹„í™œì„±í™” Vector Store í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ì „ì²˜ë¦¬ ë¹„í™œì„±í™” Vector Store í…ŒìŠ¤íŠ¸")
    try:
        vector_store_no_prep = PatentVectorStore(
            embedding_manager=embedding_manager,
            collection_name="test_no_preprocessing",
            persist_directory="./data/chroma_test",
            reset_collection=True,
            enable_preprocessing=False,
        )

        # ì²­í¬ ì €ì¥
        success_count, error_count = vector_store_no_prep.add_document_chunks_batch(
            sample_chunks
        )

        print(
            f"  âœ… ì „ì²˜ë¦¬ ì—†ì´ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨"
        )

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        search_results = vector_store_no_prep.search_similar(
            query="machine learning hardware monitoring",
            n_results=2,
            include_distances=True,
        )

        print(f"  ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(search_results.get('results', []))}ê°œ")
        for i, result in enumerate(search_results.get("results", [])[:2]):
            print(f"    {i+1}. ê±°ë¦¬: {result.get('distance', 'N/A'):.4f}")
            print(f"       ë‚´ìš©: {result['content'][:80]}...")

    except Exception as e:
        print(f"  âŒ ì „ì²˜ë¦¬ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # 4. ì „ì²˜ë¦¬ í™œì„±í™” Vector Store í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ì „ì²˜ë¦¬ í™œì„±í™” Vector Store í…ŒìŠ¤íŠ¸")
    try:
        vector_store_with_prep = PatentVectorStore(
            embedding_manager=embedding_manager,
            collection_name="test_with_preprocessing",
            persist_directory="./data/chroma_test",
            reset_collection=True,
            enable_preprocessing=True,
        )

        # ì²­í¬ ì €ì¥
        success_count, error_count = vector_store_with_prep.add_document_chunks_batch(
            sample_chunks
        )

        print(
            f"  âœ… ì „ì²˜ë¦¬ ì ìš©í•˜ì—¬ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨"
        )

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        search_results = vector_store_with_prep.search_similar(
            query="machine learning hardware monitoring",
            n_results=2,
            include_distances=True,
        )

        print(f"  ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(search_results.get('results', []))}ê°œ")
        for i, result in enumerate(search_results.get("results", [])[:2]):
            print(f"    {i+1}. ê±°ë¦¬: {result.get('distance', 'N/A'):.4f}")
            print(f"       ë‚´ìš©: {result['content'][:80]}...")

            # ì „ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° í™•ì¸
            if result["metadata"].get("preprocessing_applied"):
                print(
                    f"       ì „ì²˜ë¦¬ ì ìš©ë¨ - ì••ì¶•ë¹„ìœ¨: {result['metadata'].get('compression_ratio', 0):.3f}"
                )

    except Exception as e:
        print(f"  âŒ ì „ì²˜ë¦¬ í™œì„±í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # 5. ì„±ëŠ¥ ë¹„êµ
    print("\n5ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ")
    try:
        # í†µê³„ ì •ë³´ ë¹„êµ
        stats_no_prep = vector_store_no_prep.get_stats()
        stats_with_prep = vector_store_with_prep.get_stats()

        print("  ğŸ“Š ì „ì²˜ë¦¬ ì—†ìŒ:")
        print(f"    - ì´ ì²­í¬ ìˆ˜: {stats_no_prep.get('total_chunks', 0)}")

        print("  ğŸ“Š ì „ì²˜ë¦¬ ì ìš©:")
        print(f"    - ì´ ì²­í¬ ìˆ˜: {stats_with_prep.get('total_chunks', 0)}")

        # ì„ë² ë”© ë§¤ë‹ˆì € í†µê³„
        embedding_stats = embedding_manager.get_stats()
        print(f"  ğŸ“Š ì´ í† í° ì‚¬ìš©ëŸ‰: {embedding_stats.get('total_tokens_used', 0)}")
        print(f"  ğŸ“Š ì´ API í˜¸ì¶œ ìˆ˜: {embedding_stats.get('total_requests', 0)}")

    except Exception as e:
        print(f"  âŒ ì„±ëŠ¥ ë¹„êµ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    test_integrated_preprocessing()

    print("\n" + "=" * 80)
    print("ğŸ‰ ì „ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)
